{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f595cd-ed40-4bea-8ca9-dfe8b2c90443",
   "metadata": {},
   "source": [
    "# PySpark - where() and filter()\n",
    "## PySpark Where Filter Function | Multiple Conditions\n",
    "PySpark filter() function is used to filter the rows from RDD/DataFrame based on the given condition or SQL expression, you can also use where() clause instead of the filter() if you are coming from an SQL background, both these functions operate exactly the same.\n",
    "### PySpark DataFrame filter() Syntax\n",
    "Below is syntax of the filter function. condition would be an expression you wanted to filter.<br>\n",
    "filter(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17880bc4-aa2d-4ef8-89e5-9fcdfdf7c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb79e7a-45f5-4709-9cde-bc2c8aaf78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Anna, Rose, ]        |[Spark, Java, C++]|NY   |F     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Maria, Anne, Jones]  |[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]    |[CSharp, VB]      |NY   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField \n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "        \n",
    "schema = StructType([\n",
    "     StructField('name', StructType([\n",
    "        StructField('firstname', StringType(), True),\n",
    "        StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "\n",
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e083ee-42aa-40a2-bd4d-351cd43d4390",
   "metadata": {},
   "source": [
    "### DataFrame filter() with Column Condition\n",
    "Use Column with the condition to filter the rows from DataFrame, using this you can express complex condition by referring column names using dfObject.colname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68270da9-7116-4449-b1c9-5d055a850e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using equals condition\n",
    "df.filter(df.state == \"OH\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472a9014-5888-412f-a2e9-721d918dfcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n",
      "+--------------------+------------------+-----+------+\n",
      "|name                |languages         |state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|[Anna, Rose, ]      |[Spark, Java, C++]|NY   |F     |\n",
      "|[Maria, Anne, Jones]|[CSharp, VB]      |NY   |M     |\n",
      "|[Jen, Mary, Brown]  |[CSharp, VB]      |NY   |M     |\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# not equals condition\n",
    "df.filter(df.state != \"OH\") \\\n",
    "    .show(truncate=False) \n",
    "df.filter(~(df.state == \"OH\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5865fe51-9dda-4d3d-ae07-e1ad4297dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Julia, , Williams]   |[CSharp, VB]      |OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using SQL col() function\n",
    "from pyspark.sql.functions import col\n",
    "df.filter(col(\"state\") == \"OH\") \\\n",
    "    .show(truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a032a1-6e94-4419-ad79-f8cc14ecd4ba",
   "metadata": {},
   "source": [
    "### DataFrame filter() with SQL Expression\n",
    "If you are coming from SQL background, you can use that knowledge in PySpark to filter DataFrame rows with SQL expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7781178f-66c9-48d6-bd98-6c9932e62095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n",
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n",
      "+-------------------+------------------+-----+------+\n",
      "|               name|         languages|state|gender|\n",
      "+-------------------+------------------+-----+------+\n",
      "|     [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "+-------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using SQL Expression\n",
    "df.filter(\"gender == 'M'\").show()\n",
    "#For not equal\n",
    "df.filter(\"gender != 'M'\").show()\n",
    "df.filter(\"gender <> 'M'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497c0f4-28ef-4617-9c00-e5f3c13e7bd8",
   "metadata": {},
   "source": [
    "### PySpark Filter with Multiple Conditions\n",
    "In PySpark, to filter() rows on DataFrame based on multiple conditions, you case use either Column with a condition or SQL expression. Below is just a simple example using AND (&) condition, you can extend this with OR(|), and NOT(!) conditional expressions as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f96e18-460a-4424-b774-1b9c0b6c2c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+-----+------+\n",
      "|name                  |languages         |state|gender|\n",
      "+----------------------+------------------+-----+------+\n",
      "|[James, , Smith]      |[Java, Scala, C++]|OH   |M     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]      |OH   |M     |\n",
      "+----------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter multiple condition\n",
    "df.filter( (df.state  == \"OH\") & (df.gender  == \"M\") ) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0017c99-9dd7-4e58-aab9-f324d5be134b",
   "metadata": {},
   "source": [
    "### Filter Based on List Values\n",
    "If you have a list of elements and you wanted to filter that is not in the list or in the list, use isin() function of Column class and it doesnâ€™t have isnotin() function but you do the same using not operator (~)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "972b08cd-79ef-41e4-9728-fdcd8b221395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter IS IN List values\n",
    "li=[\"OH\",\"CA\",\"DE\"]\n",
    "df.filter(df.state.isin(li)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d91630-db0c-4c63-be77-d401580d248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n",
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter NOT IS IN List values\n",
    "#These show all records with NY (NY is not part of the list)\n",
    "df.filter(~df.state.isin(li)).show()\n",
    "df.filter(df.state.isin(li)==False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc3b205-1242-4459-af0b-96bb2525a60c",
   "metadata": {},
   "source": [
    "### Filter Based on Starts With, Ends With, Contains\n",
    "You can also filter DataFrame rows by using startswith(), endswith() and contains() methods of Column class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b87d8249-651c-4012-bef6-7aeb7cf87e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|      [Anna, Rose, ]|[Spark, Java, C++]|   NY|     F|\n",
      "|[Maria, Anne, Jones]|      [CSharp, VB]|   NY|     M|\n",
      "|  [Jen, Mary, Brown]|      [CSharp, VB]|   NY|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n",
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n",
      "+--------------------+------------------+-----+------+\n",
      "|                name|         languages|state|gender|\n",
      "+--------------------+------------------+-----+------+\n",
      "|    [James, , Smith]|[Java, Scala, C++]|   OH|     M|\n",
      "| [Julia, , Williams]|      [CSharp, VB]|   OH|     F|\n",
      "|[Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n",
      "+--------------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using startswith\n",
    "df.filter(df.state.startswith(\"N\")).show()\n",
    "\n",
    "#using endswith\n",
    "df.filter(df.state.endswith(\"H\")).show()\n",
    "\n",
    "#contains\n",
    "df.filter(df.state.contains(\"H\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0087d-ec6f-49cb-98b8-2bfb42bc20bb",
   "metadata": {},
   "source": [
    "### PySpark Filter like and rlike\n",
    "If you have SQL background you must be familiar with like and rlike (regex like), PySpark also provides similar methods in Column class to filter similar values using wildcard characters. You can use rlike() to filter by checking values case insensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5af4778-fc12-43cc-8aa4-330442311fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|      name|\n",
      "+---+----------+\n",
      "|  5|Rames rose|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),\n",
    "     (4,\"Rames Rose\"),(5,\"Rames rose\")\n",
    "  ]\n",
    "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
    "\n",
    "# like - SQL LIKE pattern\n",
    "df2.filter(df2.name.like(\"%rose%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a92b977a-9024-4443-90a7-a48c78991d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+\n",
      "| id|        name|\n",
      "+---+------------+\n",
      "|  2|Michael Rose|\n",
      "|  4|  Rames Rose|\n",
      "|  5|  Rames rose|\n",
      "+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rlike - SQL RLIKE pattern (LIKE with Regex)\n",
    "#This check case insensitive\n",
    "df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837e915-2bcd-473a-b233-d8db578c9752",
   "metadata": {},
   "source": [
    "### Filter on an Array column\n",
    "When you want to filter rows from DataFrame based on value present in an array collection column, you can use the first syntax. The below example uses array_contains() from Pyspark SQL functions which checks if a value contains in an array if present it returns true otherwise false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360157f2-fc43-472e-aea2-10b377c68b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+-----+------+\n",
      "|name            |languages         |state|gender|\n",
      "+----------------+------------------+-----+------+\n",
      "|[James, , Smith]|[Java, Scala, C++]|OH   |M     |\n",
      "|[Anna, Rose, ]  |[Spark, Java, C++]|NY   |F     |\n",
      "+----------------+------------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "df.filter(array_contains(df.languages,\"Java\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72171713-b00e-4ee2-8cff-9d062009b326",
   "metadata": {},
   "source": [
    "### Filtering on Nested Struct columns\n",
    "If your DataFrame consists of nested struct columns, you can use any of the above syntaxes to filter the rows based on the nested column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4461a555-f948-4be7-b530-a211c9db852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+-----+------+\n",
      "|name                  |languages   |state|gender|\n",
      "+----------------------+------------+-----+------+\n",
      "|[Julia, , Williams]   |[CSharp, VB]|OH   |F     |\n",
      "|[Mike, Mary, Williams]|[Python, VB]|OH   |M     |\n",
      "+----------------------+------------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Struct condition\n",
    "df.filter(df.name.lastname == \"Williams\") \\\n",
    "    .show(truncate=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
