{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5347087e-1683-4a9a-b981-cd194a670f36",
   "metadata": {},
   "source": [
    "# PySpark - withColumnRenamed()\n",
    "## PySpark withColumnRenamed to Rename Column on DataFrame\n",
    "Use PySpark withColumnRenamed() to rename a DataFrame column, we often need to rename one column or multiple (or all) columns on PySpark DataFrame, you can do this in several ways. When columns are nested it becomes complicated.<br>\n",
    "Since DataFrame’s are an immutable collection, you can’t rename or update a column instead when using withColumnRenamed() it creates a new DataFrame with updated column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf08778-8296-4c52-aac3-146e73910f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d67cf9c2-aafc-4835-ab5d-c1bba0eab250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b4dda-7f31-475a-9a63-c20810d7964c",
   "metadata": {},
   "source": [
    "### PySpark withColumnRenamed – To rename DataFrame column name\n",
    "PySpark has a withColumnRenamed() function on DataFrame to change a column name. This is the most straight forward approach; this function takes two parameters; the first is your existing column name and the second is the new column name you wish for.\n",
    "#### PySpark withColumnRenamed() Syntax:\n",
    "withColumnRenamed(existingName, newNam)\n",
    "<br>existingName – The existing column name you want to change\n",
    "<br>newName – New name of the column\n",
    "<br>Returns a new DataFrame with a column renamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b37b9a5a-f69d-4697-9c41-7da96e04d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f667381-1a00-4881-9b8c-6991b4c1c220",
   "metadata": {},
   "source": [
    "### PySpark withColumnRenamed – To rename multiple columns\n",
    "To change multiple column names, we should chain withColumnRenamed functions as shown below. You can also store all columns to rename in a list and loop through to rename all columns, I will leave this to you to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be98cd0e-5d9e-45e0-b2e0-446e9939c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184b2ad-6a19-4023-bf13-74c63a00026c",
   "metadata": {},
   "source": [
    "### Using PySpark StructType – To rename a nested column in Dataframe\n",
    "Changing a column name on nested data is not straight forward and we can do this by creating a new schema with new DataFrame columns using StructType and use it using cast function as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c58fddc-b284-4bb8-9a90-a0df7ff7824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "\n",
    "df.select(col(\"name\").cast(schema2), \\\n",
    "     col(\"dob\"), col(\"gender\"),col(\"salary\")) \\\n",
    "   .printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ef764-769a-472e-a2d7-e5cd82ad90a2",
   "metadata": {},
   "source": [
    "### Using Select – To rename nested elements.\n",
    "Let’s see another way to change nested columns by transposing the structure to flat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe201db-cbf7-4cdb-a7b5-596f26b3514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(col(\"name.firstname\").alias(\"fname\"), \\\n",
    "  col(\"name.middlename\").alias(\"mname\"), \\\n",
    "  col(\"name.lastname\").alias(\"lname\"), \\\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca665cc-305b-4b2e-a581-00cb7c2f63d8",
   "metadata": {},
   "source": [
    "### Using PySpark DataFrame withColumn – To rename nested columns\n",
    "When you have nested columns on PySpark DatFrame and if you want to rename it, use withColumn on a data frame object to create a new column from an existing and we will need to drop the existing column. Below example creates a “fname” column from “name.firstname” and drops the “name” column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8b1670-b5b0-4571-a67c-eaff1e90e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45df00-3580-4701-8525-091a9895ec29",
   "metadata": {},
   "source": [
    "### Using toDF() – To change all columns in a PySpark DataFrame\n",
    "When we have data in a flat structure (without nested) , use toDF() with a new schema to change all column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e4a4b3d-ddb9-4063-bf31-441f359113d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
