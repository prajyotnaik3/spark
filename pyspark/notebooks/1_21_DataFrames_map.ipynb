{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7975f924-ebdc-45dc-b92a-fa4aa6a55ce7",
   "metadata": {},
   "source": [
    "## PySpark map() Transformation\n",
    "PySpark map (map()) is an RDD transformation that is used to apply the transformation function (lambda) on every element of RDD/DataFrame and returns a new RDD.<br>\n",
    "RDD map() transformation is used to apply any complex operations like adding a column, updating a column, transforming the data e.t.c, the output of map transformations would always have the same number of records as input.\n",
    "* Note1: DataFrame doesn’t have map() transformation to use with DataFrame hence you need to DataFrame to RDD first.\n",
    "* Note2: If you have a heavy initialization use PySpark mapPartitions() transformation instead of map(), as with mapPartitions() heavy initialization executes only once for each partition instead of every record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23df0692-6be0-4a9c-b21b-973b3539b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d734f1a-a62c-471f-a9ac-9dbde5b27739",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"Project\",\"Gutenberg’s\",\"Alice’s\",\"Adventures\",\n",
    "\"in\",\"Wonderland\",\"Project\",\"Gutenberg’s\",\"Adventures\",\n",
    "\"in\",\"Wonderland\",\"Project\",\"Gutenberg’s\"]\n",
    "\n",
    "rdd=spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9a2cd-7735-4750-a882-0b7c7186b219",
   "metadata": {},
   "source": [
    "### map() Syntax\n",
    "map(f, preservesPartitioning=False)\n",
    "\n",
    "In this PySpark map() example, we are adding a new element with value 1 for each element, the result of the RDD is PairRDDFunctions which contains key-value pairs, word of type String as Key and 1 of type Int as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc28e0b-812f-4aa2-a518-09a6b5044f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Project', 1)\n",
      "('Gutenberg’s', 1)\n",
      "('Alice’s', 1)\n",
      "('Adventures', 1)\n",
      "('in', 1)\n",
      "('Wonderland', 1)\n",
      "('Project', 1)\n",
      "('Gutenberg’s', 1)\n",
      "('Adventures', 1)\n",
      "('in', 1)\n",
      "('Wonderland', 1)\n",
      "('Project', 1)\n",
      "('Gutenberg’s', 1)\n"
     ]
    }
   ],
   "source": [
    "rdd2=rdd.map(lambda x: (x,1))\n",
    "for element in rdd2.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdd44c-e4c1-4698-8d2c-3134f01c83f6",
   "metadata": {},
   "source": [
    "### PySpark map() with DataFrame\n",
    "PySpark DataFrame doesn’t have map() transformation to apply the lambda function, when you wanted to apply the custom transformation, you need to convert the DataFrame to RDD and apply the map() transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc628b9-2744-4f15-994c-41f416bd8587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+------+\n",
      "|firstname|lastname|gender|salary|\n",
      "+---------+--------+------+------+\n",
      "|    James|   Smith|     M|    30|\n",
      "|     Anna|    Rose|     F|    41|\n",
      "|   Robert|Williams|     M|    62|\n",
      "+---------+--------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('James','Smith','M',30),\n",
    "  ('Anna','Rose','F',41),\n",
    "  ('Robert','Williams','M',62), \n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b946449e-24ed-45e2-91ec-663ef5eddd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+\n",
      "|           name|gender|new_salary|\n",
      "+---------------+------+----------+\n",
      "|    James,Smith|     M|        60|\n",
      "|      Anna,Rose|     F|        82|\n",
      "|Robert,Williams|     M|       124|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Refering columns by index.\n",
    "rdd2=df.rdd.map(lambda x: \n",
    "    (x[0]+\",\"+x[1],x[2],x[3]*2)\n",
    "    )  \n",
    "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0daae0-ca2c-4358-9da8-cf6235f65258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+\n",
      "|           name|gender|new_salary|\n",
      "+---------------+------+----------+\n",
      "|    James,Smith|     M|        60|\n",
      "|      Anna,Rose|     F|        82|\n",
      "|Robert,Williams|     M|       124|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Referring Column Names\n",
    "rdd2=df.rdd.map(lambda x: \n",
    "    (x[\"firstname\"]+\",\"+x[\"lastname\"],x[\"gender\"],x[\"salary\"]*2)\n",
    "    )\n",
    "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b81e850-b9ab-4642-bfa2-2ce09cb74030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+\n",
      "|           name|gender|new_salary|\n",
      "+---------------+------+----------+\n",
      "|    James,Smith|     M|        60|\n",
      "|      Anna,Rose|     F|        82|\n",
      "|Robert,Williams|     M|       124|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Referring Column Names\n",
    "rdd2=df.rdd.map(lambda x: \n",
    "    (x.firstname+\",\"+x.lastname,x.gender,x.salary*2)\n",
    "    ) \n",
    "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148b49d1-7a21-4193-88b2-4deee3c8aab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+----------+\n",
      "|           name|gender|new_salary|\n",
      "+---------------+------+----------+\n",
      "|    James,Smith|     m|        60|\n",
      "|      Anna,Rose|     f|        82|\n",
      "|Robert,Williams|     m|       124|\n",
      "+---------------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By Calling function\n",
    "def func1(x):\n",
    "    firstName=x.firstname\n",
    "    lastName=x.lastname\n",
    "    name=firstName+\",\"+lastName\n",
    "    gender=x.gender.lower()\n",
    "    salary=x.salary*2\n",
    "    return (name,gender,salary)\n",
    "\n",
    "rdd2=df.rdd.map(lambda x: func1(x))\n",
    "df2=rdd2.toDF([\"name\",\"gender\",\"new_salary\"]   )\n",
    "df2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
