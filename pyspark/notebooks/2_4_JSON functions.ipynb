{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c59ce1a0-672a-4dfc-a547-a1ca61e5554a",
   "metadata": {},
   "source": [
    "### PySpark JSON Functions\n",
    "PySpark JSON functions are used to query or extract the elements from JSON string of DataFrame column by path, convert it to struct, mapt type e.t.c\n",
    "* from_json() – Converts JSON string into Struct type or Map type.\n",
    "* to_json() – Converts MapType or Struct type to JSON string.\n",
    "* json_tuple() – Extract the Data from JSON and create them as a new columns.\n",
    "* get_json_object() – Extracts JSON element from a JSON string based on json path specified.\n",
    "* schema_of_json() – Create schema string from JSON string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ecc02a-1268-4b59-b4b2-45f9c36f445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7396560-2c68-4bac-8e4f-0df576d4e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|id |value                                                                     |\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "jsonString=\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"\n",
    "df=spark.createDataFrame([(1, jsonString)],[\"id\",\"value\"])\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b2012-8df4-4f5a-ad79-fcb552dc30b7",
   "metadata": {},
   "source": [
    "#### from_json()\n",
    "PySpark from_json() function is used to convert JSON string into Struct type or Map type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2d3eda2-7661-4e50-ad97-50f55f37d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+---+---------------------------------------------------------------------------+\n",
      "|id |value                                                                      |\n",
      "+---+---------------------------------------------------------------------------+\n",
      "|1  |[Zipcode -> 704, ZipCodeType -> STANDARD, City -> PARC PARQUE, State -> PR]|\n",
      "+---+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert JSON string column to Map type\n",
    "from pyspark.sql.types import MapType,StringType\n",
    "from pyspark.sql.functions import from_json\n",
    "df2=df.withColumn(\"value\",from_json(df.value,MapType(StringType(),StringType())))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856ca23e-b193-4c6c-8784-f8ae56f7c44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- Zipcode: integer (nullable = true)\n",
      " |    |-- ZipCodeType: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      "\n",
      "+---+--------------------------------+\n",
      "|id |value                           |\n",
      "+---+--------------------------------+\n",
      "|1  |[704, STANDARD, PARC PARQUE, PR]|\n",
      "+---+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "schema = StructType([\n",
    "    StructField(\"Zipcode\", IntegerType(), True),\n",
    "    StructField(\"ZipCodeType\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True)\n",
    "])\n",
    "\n",
    "df3=df.withColumn(\"value\", from_json(df.value, schema))\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f204dc-8583-4073-934d-2186910824e5",
   "metadata": {},
   "source": [
    "#### to_json()\n",
    "to_json() function is used to convert DataFrame columns MapType or Struct type to JSON string. Here, I am using df2 that created from above from_json() example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f2aec4-070c-425d-95ec-64943b80414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------+\n",
      "|id |value                                                                       |\n",
      "+---+----------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":\"704\",\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+----------------------------------------------------------------------------+\n",
      "\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|id |value                                                                     |\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json, col\n",
    "df2.withColumn(\"value\",to_json(col(\"value\"))) \\\n",
    "   .show(truncate=False)\n",
    "df3.withColumn(\"value\",to_json(col(\"value\"))) \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9709f4-fb79-4b71-bf3e-36b6246df406",
   "metadata": {},
   "source": [
    "#### json_tuple()\n",
    "Function json_tuple() is used the query or extract the elements from JSON column and create the result as a new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cb3c14-ec3b-4813-8b0d-40488941def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+-----------+-----+\n",
      "|id |Zipcode|ZipCodeType|City       |State|\n",
      "+---+-------+-----------+-----------+-----+\n",
      "|1  |704    |STANDARD   |PARC PARQUE|PR   |\n",
      "+---+-------+-----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import json_tuple\n",
    "df.select(col(\"id\"),json_tuple(col(\"value\"),\"Zipcode\",\"ZipCodeType\",\"City\", \"State\")) \\\n",
    "    .toDF(\"id\",\"Zipcode\",\"ZipCodeType\",\"City\", \"State\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1bdf2a-3068-4db9-8653-1c3c6af09fa1",
   "metadata": {},
   "source": [
    "#### get_json_object()\n",
    "get_json_object() is used to extract the JSON string based on path from the JSON column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5562f871-5d4a-4d5f-b331-9e4123a1a83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "|id |ZipCodeType|\n",
      "+---+-----------+\n",
      "|1  |STANDARD   |\n",
      "+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object\n",
    "df.select(col(\"id\"),get_json_object(col(\"value\"),\"$.ZipCodeType\").alias(\"ZipCodeType\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef1349-674d-4e5b-bd04-e2cf35c99ea2",
   "metadata": {},
   "source": [
    "#### schema_of_json()\n",
    "Use schema_of_json() to create schema string from JSON string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84b076ba-7815-4366-9a17-62d1f4dd2259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct<City:string,State:string,ZipCodeType:string,Zipcode:bigint>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import schema_of_json,lit\n",
    "schemaStr=spark.range(1) \\\n",
    "    .select(schema_of_json(lit(\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"))) \\\n",
    "    .collect()[0][0]\n",
    "print(schemaStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2305c5d1-4cac-4235-b834-78aaa9091187",
   "metadata": {},
   "source": [
    "|Category|Functions|\n",
    "|--------|---------|\n",
    "|Aggregate Functions|approxCountDistinct, avg, count, countDistinct, first, last, max, mean, min, sum, sumDistinct|\n",
    "|Collection Functions|array_contains, explode, size, sort_array|\n",
    "|Date/time Functions|<b>Date/timestamp conversion</b>:<br>unix_timestamp, from_unixtime, to_date, quarter, day, dayofyear, weekofyear, from_utc_timestamp, to_utc_timestamp<br><b>Extracting fields from a date/timestamp value:</b><br>year, month, dayofmonth, hour, minute, second<br><b>Date/timestamp calculation:</b><br>datediff, date_add, date_sub, add_months, last_day, next_day, months_between<br><b>Misc.:</b><br>current_date, current_timestamp, trunc, date_format|\n",
    "|Math Functions|abs, acros, asin, atan, atan2, bin, cbrt, ceil, conv, cos, sosh, exp, expm1, factorial, floor, hex, hypot, log, log10, log1p, log2, pmod, pow, rint, round, shiftLeft, shiftRight, shiftRightUnsigned, signum, sin, sinh, sqrt, tan, tanh, toDegrees, toRadians, unhex|\n",
    "|Misc. Functions|array, bitwiseNOT, callUDF, coalesce, crc32, greatest, if, inputFileName, isNaN, isnotnull, isnull, least, lit, md5, monotonicallyIncreasingId, nanvl, negate, not, rand, randn, sha, sha1, sparkPartitionId, struct, when|\n",
    "|String Functions|ascii, base64, concat, concat_ws, decode, encode, format_number, format_string, get_json_object, initcap, instr, length, levenshtein, locate, lower, lpad, ltrim, printf, regexp_extract, regexp_replace, repeat, reverse, rpad, rtrim, soundex, space, split, substring, substring_index, translate, trim, unbase64, upper|\n",
    "|Window Functions (in addition to Aggregate Functions)|cumeDist, denseRank, lag, lead, ntile, percentRank, rank, rowNumber|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
