{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95a9905-900e-4d57-a743-9a458bbe144d",
   "metadata": {},
   "source": [
    "## PySpark StructType & StructField\n",
    "PySpark StructType & StructField classes are used to programmatically specify the schema to the DataFrame and create complex columns like nested struct, array, and map columns. StructType is a collection of StructField’s that defines column name, column data type, boolean to specify if the field can be nullable or not and metadata.<br>\n",
    "Though PySpark infers a schema from data, sometimes we may need to define our own column names and data types.<br>\n",
    "### StructType – Defines the structure of the Dataframe\n",
    "PySpark provides from pyspark.sql.types import StructType class to define the structure of the DataFrame. StructType is a collection or list of StructField objects.<br>\n",
    "PySpark printSchema() method on the DataFrame shows StructType columns as struct. <br>\n",
    "### StructField – Defines the metadata of the DataFrame column\n",
    "PySpark provides pyspark.sql.types import StructField class to define the columns which include column name(String), column type (DataType), nullable column (Boolean) and metadata (MetaData) \n",
    "### Using PySpark StructType & StructField with DataFrame\n",
    "While creating a PySpark DataFrame we can specify the structure using StructType and StructField classes. As specified in the introduction, StructType is a collection of StructField’s which is used to define the column name, data type, and a flag for nullable or not. Using StructField we can also add nested struct schema, ArrayType for arrays, and MapType for key-value pairs which we will discuss in detail in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4210e1-0c96-4a8a-9f41-8f0a8cc8c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736a5682-fe6a-4a20-99d7-5d7deedcd600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed6abd-2239-43c7-8cb1-da14cffd7880",
   "metadata": {},
   "source": [
    "## Defining Nested StructType object struct\n",
    "While working on DataFrame we often need to work with the nested struct column and this can be defined using StructType. <br>\n",
    "In the below example column “name” data type is StructType which is nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e6a997a-02e4-4e80-a853-b9a44b50c41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|[James, , Smith]    |36636|M     |3100  |\n",
      "|[Michael, Rose, ]   |40288|M     |4300  |\n",
      "|[Robert, , Williams]|42114|M     |1400  |\n",
      "|[Maria, Anne, Jones]|39192|F     |5500  |\n",
      "|[Jen, Mary, Brown]  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fc626-be22-482e-9adf-03e3dd5fa77f",
   "metadata": {},
   "source": [
    "## Adding & Changing struct of the DataFrame\n",
    "Using PySpark SQL function struct(), we can change the struct of the existing DataFrame and add a new StructType to it. <br>\n",
    "PySpark Column Class also provides some functions to work with the StructType column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ff0867-0a66-48b5-ba74-99e35bf81b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n",
      "+--------------------+------------------------+\n",
      "|name                |OtherInfo               |\n",
      "+--------------------+------------------------+\n",
      "|[James, , Smith]    |[36636, M, 3100, Medium]|\n",
      "|[Michael, Rose, ]   |[40288, M, 4300, High]  |\n",
      "|[Robert, , Williams]|[42114, M, 1400, Low]   |\n",
      "|[Maria, Anne, Jones]|[39192, F, 5500, High]  |\n",
      "|[Jen, Mary, Brown]  |[, F, -1, Low]          |\n",
      "+--------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,struct,when\n",
    "updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "    struct(col(\"id\").alias(\"identifier\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"salary\").alias(\"salary\"),\n",
    "    when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "      .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "      .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "  )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updatedDF.printSchema()\n",
    "updatedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc9b7a7-212b-4479-8887-09b947e3d198",
   "metadata": {},
   "source": [
    "## Using SQL ArrayType and MapType\n",
    "SQL StructType also supports ArrayType and MapType to define the DataFrame columns for array and map collections respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0738c49d-4b06-42ba-aeb5-459571e2841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- hobbies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import ArrayType, MapType\n",
    "arrayStructureSchema = StructType([\n",
    "    StructField('name', StructType([\n",
    "       StructField('firstname', StringType(), True),\n",
    "       StructField('middlename', StringType(), True),\n",
    "       StructField('lastname', StringType(), True)\n",
    "       ])),\n",
    "       StructField('hobbies', ArrayType(StringType()), True),\n",
    "       StructField('properties', MapType(StringType(),StringType()), True)\n",
    "    ])\n",
    "emptyRDD2 = spark.createDataFrame([], arrayStructureSchema)\n",
    "emptyRDD2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903a606-4562-4cab-ba66-c867e7df06f1",
   "metadata": {},
   "source": [
    "## Creating StructType object struct from JSON file\n",
    "If you have too many columns and the structure of the DataFrame changes now and then, it’s a good practice to load the SQL StructType schema from JSON file. You can get the schema by using df2.schema.json() , store this in a file and will use it to create a the schema from this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "023323de-da00-4b93-aba2-63baf34ca170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fields\":[{\"metadata\":{},\"name\":\"name\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"firstname\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"middlename\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"lastname\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"gender\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary\",\"nullable\":true,\"type\":\"integer\"}],\"type\":\"struct\"}\n"
     ]
    }
   ],
   "source": [
    "print(df2.schema.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b56ff11-df77-41a1-9aca-f98d13b2538e",
   "metadata": {},
   "source": [
    "Alternatively, you could also use df.schema.simpleString(), this will return an relatively simpler schema format.\n",
    "Now let’s load the json file and use it to create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23b1374-8169-44a0-a79d-3d5d594e2b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "schemaFromJson = StructType.fromJson(json.loads(df2.schema.json()))\n",
    "df3 = spark.createDataFrame(\n",
    "        spark.sparkContext.parallelize(structureData),schemaFromJson)\n",
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861821ec-1157-4237-9805-045e473a11b0",
   "metadata": {},
   "source": [
    "## Creating StructType object struct from DDL String\n",
    "Like loading structure from JSON string, we can also create it from DDL ( by using fromDDL() static function on SQL StructType class StructType.fromDDL). You can also generate DDL from a schema using toDDL(). printTreeString() on struct object prints the schema similar to printSchemafunction returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f792e2-77ab-4ed2-93c1-6e04a88d8864",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'StructType' has no attribute 'fromDDL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15704\\2294634333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mddlSchemaStr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"`fullName` STRUCT<`first`: STRING, `last`: STRING, `middle`: STRING>,`age` INT,`gender` STRING\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mddlSchema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStructType\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromDDL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mddlSchemaStr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mddlSchema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintTreeString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'StructType' has no attribute 'fromDDL'"
     ]
    }
   ],
   "source": [
    "ddlSchemaStr = \"`fullName` STRUCT<`first`: STRING, `last`: STRING, `middle`: STRING>,`age` INT,`gender` STRING\"\n",
    "ddlSchema = StructType.fromDDL(ddlSchemaStr)\n",
    "ddlSchema.printTreeString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a32b09-6095-43ca-aecb-fb12687a139c",
   "metadata": {},
   "source": [
    "## Checking if a Column Exists in a DataFrame\n",
    "If you want to perform some checks on metadata of the DataFrame, for example, if a column or field exists in a DataFrame or data type of column; we can easily do this using several functions on SQL StructType and StructField."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c53b1be-735d-4cf2-9602-c8781c2885f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"firstname\" in df.schema.fieldNames())\n",
    "print(StructField(\"firstname\",StringType(),True) in df.schema)\n",
    "print(StructField(\"firstname\",IntegerType(),True) in df.schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
